# KnowledgeVault Configuration
# Copy this file to .env and customize the values

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
PORT=8080

# Data Directory Configuration
# Host path for Docker volume mount - path on your host machine where data will be persisted
HOST_DATA_DIR=./data
# Container path for data storage - path inside the Docker container
DATA_DIR=/data/knowledgevault

# =============================================================================
# AUTHENTICATION & SECURITY
# =============================================================================
# Admin API key for accessing protected endpoints.
# Set to a secure random string to enable authentication.
# Leave as default "admin-secret-token" to disable authentication (development mode).
# Generate a secure key: openssl rand -base64 32
ADMIN_SECRET_TOKEN=admin-secret-token

# Rate limiting for admin endpoints (e.g., "10/minute")
ADMIN_RATE_LIMIT=10/minute

# Health check API key for external monitoring
HEALTH_CHECK_API_KEY=health-api-key

# CSRF token time-to-live in seconds (default: 900 = 15 minutes)
CSRF_TOKEN_TTL=900

# Redis URL for CSRF token storage and caching
# Use "redis://localhost:6379/0" for local Redis
# In Docker: "redis://redis:6379/0"
REDIS_URL=redis://localhost:6379/0

# CORS allowed origins (comma-separated list)
# For development: http://localhost:5173
# For production: https://yourdomain.com
BACKEND_CORS_ORIGINS=http://localhost:5173

# =============================================================================
# OLLAMA CONFIGURATION
# =============================================================================
# URLs for embedding and chat services
# For tri-vector, point to the external FlagEmbedding server (flag-embed)
OLLAMA_EMBEDDING_URL=http://flag-embed:18080/v1/embeddings
OLLAMA_CHAT_URL=http://host.docker.internal:11434

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
EMBEDDING_MODEL=bge-m3

# Chat model for conversational responses
CHAT_MODEL=openai/gpt-oss-20b

# Embedding dimension (auto-detected, but can be overridden)
# bge-m3 = 1024
EMBEDDING_DIM=1024

# Enable model validation on startup (checks if models are available in Ollama)
ENABLE_MODEL_VALIDATION=false

# =============================================================================
# DOCUMENT PROCESSING (NEW CHARACTER-BASED CONFIGURATION)
# =============================================================================
# Character-based chunk size (~4 chars per token)
# Default: 2000 chars (~500 tokens) - compatible with llama.cpp default batch size
CHUNK_SIZE_CHARS=2000

# Character-based overlap between chunks
# Default: 200 chars (~50 tokens overlap)
CHUNK_OVERLAP_CHARS=200

# Document parsing strategy for unstructured.io
# Options: "fast" (fastest), "hi_res" (best quality), "auto" (automatic)
DOCUMENT_PARSING_STRATEGY=fast

# =============================================================================
# RETRIEVAL CONFIGURATION
# =============================================================================
# Number of top chunks to retrieve for RAG context
# This is the canonical setting (replaces MAX_CONTEXT_CHUNKS and VECTOR_TOP_K)
RETRIEVAL_TOP_K=12

# Maximum distance threshold for relevance filtering
# For cosine distance: 0=identical, 1=orthogonal, 2=opposite
# 0.5 is a good default balance between precision and recall
MAX_DISTANCE_THRESHOLD=0.5

# Distance metric for vector similarity search
# Options: "cosine", "l2", "dot"
VECTOR_METRIC=cosine

# Window size for retrieval context expansion (fetches N adjacent chunks)
RETRIEVAL_WINDOW=1

# =============================================================================
# EMBEDDING CONFIGURATION
# =============================================================================
# Number of texts to send per embedding API request
# Higher values = better GPU utilization but more VRAM usage
EMBEDDING_BATCH_SIZE=512

# Maximum retries for adaptive batching when token overflow occurs
EMBEDDING_BATCH_MAX_RETRIES=3

# Minimum sub-batch size for adaptive batching fallback
EMBEDDING_BATCH_MIN_SUB_SIZE=1

# Optional prefixes for instruction-based embedding models (e.g., Qwen3)
# Leave empty for BGE-M3 (doesn't use prefixes)
EMBEDDING_DOC_PREFIX=
EMBEDDING_QUERY_PREFIX=

# =============================================================================
# RERANKER CONFIGURATION
# =============================================================================
# Enable cross-encoder reranking for better retrieval quality
RERANKING_ENABLED=true

# Reranker endpoint URL (TEI-compatible)
# Leave empty to use local sentence-transformers
RERANKER_URL=

# Reranker model (HuggingFace model ID)
RERANKER_MODEL=BAAI/bge-reranker-v2-m3

# Number of chunks to keep after reranking
RERANKER_TOP_N=5

# Initial retrieval count before reranking
INITIAL_RETRIEVAL_TOP_K=20

# =============================================================================
# HYBRID SEARCH CONFIGURATION
# =============================================================================
# Enable hybrid search: combines dense vector + BM25 keyword search
HYBRID_SEARCH_ENABLED=true

# Weight for dense vs sparse scores in RRF fusion
# 0.0 = pure BM25, 1.0 = pure dense, 0.5 = equal weight
HYBRID_ALPHA=0.5

# =============================================================================
# BLEEDING-EDGE RAG FEATURES (enabled by default below)
# =============================================================================
# Phase 2: Contextual Chunking
CONTEXTUAL_CHUNKING_ENABLED=true
CONTEXTUAL_CHUNKING_CONCURRENCY=5

# Phase 3: Multi-Scale Chunk Indexing
MULTI_SCALE_INDEXING_ENABLED=true
MULTI_SCALE_CHUNK_SIZES=512,1024,2048
MULTI_SCALE_OVERLAP_RATIO=0.1

# Phase 4: Query Transformation
QUERY_TRANSFORMATION_ENABLED=true

# Phase 5: Retrieval Evaluation
RETRIEVAL_EVALUATION_ENABLED=true

# Phase 6: Tri-Vector Search (FlagEmbedding server)
TRI_VECTOR_SEARCH_ENABLED=true
FLAG_EMBEDDING_URL=http://flag-embed:18080

# =============================================================================
# LEGACY/DEPRECATED SETTINGS (Still supported for backward compatibility)
# =============================================================================
# [DEPRECATED] Use CHUNK_SIZE_CHARS instead
CHUNK_SIZE=512

# [DEPRECATED] Use CHUNK_OVERLAP_CHARS instead
CHUNK_OVERLAP=50

# [DEPRECATED] Use RETRIEVAL_TOP_K instead
MAX_CONTEXT_CHUNKS=10
VECTOR_TOP_K=10

# [DEPRECATED] Use MAX_DISTANCE_THRESHOLD instead
RAG_RELEVANCE_THRESHOLD=0.1

# =============================================================================
# FILE UPLOAD SECURITY
# =============================================================================
# Maximum file upload size in MB
MAX_FILE_SIZE_MB=50

# Allowed file extensions for upload (comma-separated)
ALLOWED_EXTENSIONS=.txt,.md,.pdf,.docx,.csv,.json,.sql,.py,.js,.ts,.html,.css,.xml,.yaml,.yml

# =============================================================================
# LOGGING
# =============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# =============================================================================
# AUTO-SCAN CONFIGURATION
# =============================================================================
# Enable automatic periodic scanning of data directory for new files
AUTO_SCAN_ENABLED=true
# Interval in minutes between automatic scans
AUTO_SCAN_INTERVAL_MINUTES=60

# =============================================================================
# MAINTENANCE MODE
# =============================================================================
# Enable maintenance mode (blocks document uploads and RAG queries)
MAINTENANCE_MODE=false

# =============================================================================
# IMAP EMAIL INGESTION CONFIGURATION
# =============================================================================
# Enable email ingestion via IMAP (requires valid IMAP settings below)
IMAP_ENABLED=false
# IMAP server hostname (e.g., mail.yourdomain.com)
IMAP_HOST=
# IMAP server port (default: 993 for SSL, 143 for non-SSL)
IMAP_PORT=993
# Use SSL/TLS for IMAP connection (true for port 993, false for port 143)
IMAP_USE_SSL=true
# IMAP account username (e.g., ragbot@yourdomain.com)
IMAP_USERNAME=
# IMAP account password
IMAP_PASSWORD=
# Mailbox to poll (default: INBOX)
IMAP_MAILBOX=INBOX
# Polling interval in seconds (default: 60)
IMAP_POLL_INTERVAL=60
# Maximum attachment size to process (in bytes, default: 10MB)
IMAP_MAX_ATTACHMENT_SIZE=10485760
